{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc810da-4b11-487d-8854-40911ebcc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b868da-d5a3-46c7-97f4-1f71cf18b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgmain = face_recognition.load_image_file('ImageBasics/Dahiru.jpg')\n",
    "imgmain = cv2.cvtColor(imgmain, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a31358-4b6b-45c4-af53-757699eaf70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTest = face_recognition.load_image_file('ImageBasics/bryan-cranston-el-camino-aaron-paul-1a.jpg')\n",
    "imgTest = cv2.cvtColor(imgTest, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95b955e-59b4-425f-af83-ad505622e893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[110, 125,  98],\n",
       "        [100, 115,  88],\n",
       "        [ 89, 104,  77],\n",
       "        ...,\n",
       "        [ 85, 116, 125],\n",
       "        [ 85, 116, 125],\n",
       "        [ 85, 116, 125]],\n",
       "\n",
       "       [[107, 122,  95],\n",
       "        [ 98, 113,  86],\n",
       "        [ 87, 102,  75],\n",
       "        ...,\n",
       "        [ 86, 117, 126],\n",
       "        [ 86, 117, 126],\n",
       "        [ 86, 117, 126]],\n",
       "\n",
       "       [[ 99, 113,  89],\n",
       "        [ 91, 105,  81],\n",
       "        [ 82,  96,  72],\n",
       "        ...,\n",
       "        [ 88, 119, 128],\n",
       "        [ 88, 119, 128],\n",
       "        [ 88, 119, 128]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 84,  91,  88],\n",
       "        [ 85,  92,  89],\n",
       "        [ 86,  93,  90],\n",
       "        ...,\n",
       "        [ 95, 105,  99],\n",
       "        [ 97, 107, 101],\n",
       "        [ 99, 109, 103]],\n",
       "\n",
       "       [[ 83,  90,  87],\n",
       "        [ 84,  91,  88],\n",
       "        [ 85,  92,  89],\n",
       "        ...,\n",
       "        [ 95, 103,  93],\n",
       "        [ 96, 104,  94],\n",
       "        [ 97, 105,  95]],\n",
       "\n",
       "       [[ 81,  88,  85],\n",
       "        [ 83,  90,  87],\n",
       "        [ 84,  91,  88],\n",
       "        ...,\n",
       "        [ 95, 100,  91],\n",
       "        [ 96, 101,  92],\n",
       "        [ 98, 104,  93]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceLoc = face_recognition.face_locations(imgmain)[0]\n",
    "encodeElon = face_recognition.face_encodings(imgmain)[0]\n",
    "cv2.rectangle(imgmain, (faceLoc[3], faceLoc[0]), (faceLoc[1], faceLoc[2]), (255, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f37702-281d-4897-b371-8a8f05b2a06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        ...,\n",
       "        [247, 134,  94],\n",
       "        [248, 135,  95],\n",
       "        [248, 135,  95]],\n",
       "\n",
       "       [[229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        ...,\n",
       "        [247, 134,  94],\n",
       "        [247, 134,  94],\n",
       "        [248, 135,  95]],\n",
       "\n",
       "       [[229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        ...,\n",
       "        [246, 133,  93],\n",
       "        [247, 134,  94],\n",
       "        [247, 134,  94]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 26,  21,  22],\n",
       "        [ 27,  22,  23],\n",
       "        [ 24,  19,  20],\n",
       "        ...,\n",
       "        [ 58,  53,  44],\n",
       "        [ 47,  42,  33],\n",
       "        [ 42,  37,  28]],\n",
       "\n",
       "       [[ 23,  18,  19],\n",
       "        [ 27,  22,  23],\n",
       "        [ 28,  23,  24],\n",
       "        ...,\n",
       "        [127, 122, 113],\n",
       "        [122, 117, 108],\n",
       "        [119, 114, 105]],\n",
       "\n",
       "       [[ 33,  28,  29],\n",
       "        [ 41,  36,  37],\n",
       "        [ 47,  42,  43],\n",
       "        ...,\n",
       "        [118, 113, 104],\n",
       "        [117, 112, 103],\n",
       "        [118, 113, 104]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceLocTest = face_recognition.face_locations(imgTest)[0]\n",
    "encodeTest = face_recognition.face_encodings(imgTest)[0]\n",
    "cv2.rectangle(imgTest, (faceLocTest[3], faceLocTest[0]), (faceLocTest[1], faceLocTest[2]), (255, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a176c4-cd9e-4584-97dc-67b4a17ee05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "source": [
    "results = face_recognition.compare_faces([encodeElon], encodeTest)\n",
    "faceDis = face_recognition.face_distance([encodeElon], encodeTest)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa2ab28-eb2e-484f-8567-6bd77f82c8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        ...,\n",
       "        [247, 134,  94],\n",
       "        [248, 135,  95],\n",
       "        [248, 135,  95]],\n",
       "\n",
       "       [[229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        ...,\n",
       "        [247, 134,  94],\n",
       "        [247, 134,  94],\n",
       "        [248, 135,  95]],\n",
       "\n",
       "       [[229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        [229, 121,  87],\n",
       "        ...,\n",
       "        [246, 133,  93],\n",
       "        [247, 134,  94],\n",
       "        [247, 134,  94]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 26,  21,  22],\n",
       "        [ 27,  22,  23],\n",
       "        [ 24,  19,  20],\n",
       "        ...,\n",
       "        [ 58,  53,  44],\n",
       "        [ 47,  42,  33],\n",
       "        [ 42,  37,  28]],\n",
       "\n",
       "       [[ 23,  18,  19],\n",
       "        [ 27,  22,  23],\n",
       "        [ 28,  23,  24],\n",
       "        ...,\n",
       "        [127, 122, 113],\n",
       "        [122, 117, 108],\n",
       "        [119, 114, 105]],\n",
       "\n",
       "       [[ 33,  28,  29],\n",
       "        [ 41,  36,  37],\n",
       "        [ 47,  42,  43],\n",
       "        ...,\n",
       "        [118, 113, 104],\n",
       "        [117, 112, 103],\n",
       "        [118, 113, 104]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.putText(imgTest, f'{results} {round(faceDis[0], 2)}', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ebbb3ba-dbe6-4db8-a546-f2a77cf5bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Main Image', imgmain)\n",
    "cv2.imshow('Test Image', imgTest)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc05744-a69f-44ea-b8d2-a3c83499d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Check if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break;\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404e87b-9ed1-4ce3-af1e-2473afa0e3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
